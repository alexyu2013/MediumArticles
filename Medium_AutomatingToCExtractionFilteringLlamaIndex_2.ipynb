{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "cu9doki3MkTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Setup"
      ],
      "metadata": {
        "id": "5B4QohJN6fPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJaaU0b-5Z3Q",
        "outputId": "9f113ad2-668c-4577-b538-5ac58fc49b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.11.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.2 (from llama-index)\n",
            "  Downloading llama_index_core-0.11.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.3-py3-none-any.whl.metadata (635 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.2.0-py3-none-any.whl.metadata (648 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.2->llama-index) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (3.10.5)\n",
            "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (3.3)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama-index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.15-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.2.0->llama-index)\n",
            "  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.2->llama-index) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.2->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.2->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.2->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.2->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.2->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.2->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.2->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.2->llama-index) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.2->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.2->llama-index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.2->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.2->llama-index) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.2->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.2->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.2->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.2->llama-index)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.2->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.2->llama-index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
            "Downloading llama_index-0.11.2-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.11.2-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.2.3-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.2.0-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.2.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading llama_cloud-0.0.15-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: striprtf, dirtyjson, tenacity, pypdf, nltk, mypy-extensions, marshmallow, jiter, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 llama-cloud-0.0.15 llama-index-0.11.2 llama-index-agent-openai-0.3.0 llama-index-cli-0.3.0 llama-index-core-0.11.2 llama-index-embeddings-openai-0.2.3 llama-index-indices-managed-llama-cloud-0.3.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.0 llama-index-multi-modal-llms-openai-0.2.0 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.0 llama-index-readers-llama-parse-0.2.0 llama-parse-0.5.0 marshmallow-3.22.0 mypy-extensions-1.0.0 nltk-3.9.1 openai-1.42.0 pypdf-4.3.1 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-readers-file\n",
        "!pip install llama-index-llms-openai\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEGzDswf9wlU",
        "outputId": "5195eec6-1c25-4410-c7c0-a42b84fc8d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-readers-file in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (4.12.3)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (2.1.4)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (0.0.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.5.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (24.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.2)\n",
            "Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (0.11.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (1.42.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.5.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.22.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (24.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 0s (1,237 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re,os\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from llama_index.core.node_parser import HTMLNodeParser, SentenceSplitter, SimpleFileNodeParser\n",
        "from llama_index.readers.file import FlatReader"
      ],
      "metadata": {
        "id": "Tno4jX0f-BlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Download the data files"
      ],
      "metadata": {
        "id": "8CIlUR1Z6qeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/'\n",
        "!wget 'https://arxiv.org/pdf/2403.16971' -O 'data/AIOS.pdf'\n",
        "!wget 'https://arxiv.org/pdf/2406.04692' -O 'data/Mixture_of_Agents.pdf'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9yi6a9K6tOz",
        "outputId": "c3847644-c60f-4fcd-dcac-1f906e90261a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-28 07:07:18--  https://arxiv.org/pdf/2403.16971\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.131.42, 151.101.195.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569103 (556K) [application/pdf]\n",
            "Saving to: ‘data/AIOS.pdf’\n",
            "\n",
            "\rdata/AIOS.pdf         0%[                    ]       0  --.-KB/s               \rdata/AIOS.pdf       100%[===================>] 555.76K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-08-28 07:07:19 (91.1 MB/s) - ‘data/AIOS.pdf’ saved [569103/569103]\n",
            "\n",
            "--2024-08-28 07:07:19--  https://arxiv.org/pdf/2406.04692\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.131.42, 151.101.195.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1157463 (1.1M) [application/pdf]\n",
            "Saving to: ‘data/Mixture_of_Agents.pdf’\n",
            "\n",
            "data/Mixture_of_Age 100%[===================>]   1.10M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-08-28 07:07:19 (108 MB/s) - ‘data/Mixture_of_Agents.pdf’ saved [1157463/1157463]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Define the PDF processor to extract the Table of content automatically"
      ],
      "metadata": {
        "id": "uaM-uCdJo4uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFContentProcessor:\n",
        "    def __init__(self, source_pdf):\n",
        "        self.source_pdf = source_pdf\n",
        "        self.base_name = source_pdf.rstrip('.pdf')\n",
        "        self.file_name = Path(source_pdf).name\n",
        "\n",
        "    def transform_pdf_to_html(self):\n",
        "        # Command to convert PDF to HTML using pdftohtml tool\n",
        "      # First command to generate the main HTML file\n",
        "        command = f\"pdftohtml -s -i -enc UTF-8 '{self.source_pdf}' '{self.base_name}.html'\"\n",
        "       # Second command to generate the HTML file with the table of contents (ToC)\n",
        "        command1 = f\"pdftohtml -s -i -c -hidden -noframes -zoom 1.5 '{self.source_pdf}' '{self.base_name}.html'\"\n",
        "\n",
        "\n",
        "        try:\n",
        "            subprocess.run(command, check=True, shell=True)\n",
        "            subprocess.run(command1, check=True, shell=True)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error executing command: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    def load_and_process_html(self):\n",
        "        html_path = Path(f\"./{self.base_name}.html\")\n",
        "        html_docs = FlatReader().load_data(html_path)\n",
        "        parser = HTMLNodeParser(tags=[\"p\"])\n",
        "        nodes = parser.get_nodes_from_documents(html_docs)\n",
        "        return self.improve_format(nodes[0].text)\n",
        "\n",
        "    def improve_format(self, texto):\n",
        "        texto = texto.replace('\\xa0', ' ')\n",
        "        texto = texto.replace('&#160;', ' ')\n",
        "        texto = texto.replace('\\n\\n', '\\n')\n",
        "        texto = re.sub(r'(\\.\\n)', '.\\n\\n', texto)\n",
        "        return texto\n",
        "\n",
        "    def write_in_file(self, contenido):\n",
        "        with open(f\"{self.base_name}.txt\", 'w', encoding='utf-8') as fichero:\n",
        "            fichero.write(contenido)\n",
        "\n",
        "    def split_text(self):\n",
        "        txt_path = Path(f\"{self.base_name}.txt\")\n",
        "        txt_docs = FlatReader().load_data(txt_path)\n",
        "        splitter = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
        "        return splitter.get_nodes_from_documents(txt_docs)\n",
        "\n",
        "    def process_html_toc(self):\n",
        "          with open(f\"{self.base_name}s.html\", 'r', encoding='utf-8') as file:\n",
        "              soup = BeautifulSoup(file, 'html.parser')\n",
        "\n",
        "          main_ul = soup.find('ul')\n",
        "          if not main_ul:\n",
        "              return []\n",
        "\n",
        "          list_lenght = len(main_ul.find_all('li', recursive=False))\n",
        "\n",
        "          # Setting to handle HTML structure correctly\n",
        "          if list_lenght == 1:\n",
        "              main_ul = main_ul.find('ul')\n",
        "          else:\n",
        "              if main_ul and main_ul.li:\n",
        "                  # Additional check to prevent deletion of a valid item\n",
        "                  if not main_ul.li.a or main_ul.li.a.text.strip().lower() != 'introduction':\n",
        "                      main_ul.li.decompose()\n",
        "\n",
        "          if not main_ul:\n",
        "              return []\n",
        "\n",
        "          entries = []\n",
        "          self.parse_list_items(main_ul, entries)\n",
        "          return entries\n",
        "\n",
        "    def parse_list_items(self, ul, entries, level=1):\n",
        "        items = ul.find_all('li', recursive=False)\n",
        "        for item in items:\n",
        "            a_tag = item.find('a')\n",
        "            if a_tag and 'href' in a_tag.attrs:\n",
        "                page = a_tag['href'].split('#')[1]\n",
        "                title = a_tag.text.strip()\n",
        "                levels = [False] * 3\n",
        "                if level <= 3:\n",
        "                    levels[level - 1] = True\n",
        "                entries.append([int(page), title] + levels)\n",
        "\n",
        "            nested_ul = item.find('ul')\n",
        "            if nested_ul:\n",
        "                self.parse_list_items(nested_ul, entries, level + 1)\n",
        "\n",
        "    def write_toc_to_csv(self, toc_entries):\n",
        "        with open(f\"{self.base_name}_output.csv\", 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            csvwriter = csv.writer(csvfile)\n",
        "            csvwriter.writerow(['page', 'title', 'first_level', 'second_level', 'third_level'])\n",
        "            csvwriter.writerows(toc_entries)\n",
        "\n",
        "    def read_and_prepare_sections(self):\n",
        "        df = pd.read_csv(f\"{self.base_name}_output.csv\")\n",
        "        sections_info = [{\n",
        "            'title': row['title'],\n",
        "            'page': row['page'],\n",
        "            'level': 1 if row['first_level'] else 2 if row['second_level'] else 3 if row['third_level'] else None\n",
        "        } for index, row in df.iterrows()]\n",
        "        return sections_info\n",
        "\n",
        "    def add_metadata_to_nodes(self, nodes, sections_info):\n",
        "        last_index_found_global = 0\n",
        "        for node_index, node in enumerate(nodes):\n",
        "            text_content = node.text\n",
        "            node.metadata = {\"page\": [], \"section\": [], \"file_name\": self.file_name}\n",
        "\n",
        "            found = False\n",
        "            last_index_found = last_index_found_global\n",
        "\n",
        "            for info in sections_info[last_index_found:]:\n",
        "                pattern = re.escape(info['title']) + r'\\n'\n",
        "                match = re.search(pattern, text_content)\n",
        "                if match:\n",
        "                    last_index_found_global += 1\n",
        "                    node.metadata['section'].append(info['title'])\n",
        "                    node.metadata['page'].append(info['page'])\n",
        "                    superiors = self.get_superior_sections(info['title'], sections_info)\n",
        "                    for sup_title, sup_page in superiors:\n",
        "                        if sup_title not in node.metadata['section']:\n",
        "                            node.metadata['section'].insert(0, sup_title)\n",
        "                            node.metadata['page'].insert(0, sup_page)\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if not found and node_index > 0:\n",
        "                node.metadata = nodes[node_index - 1].metadata.copy()\n",
        "\n",
        "    def get_superior_sections(self, section_title, sections_info):\n",
        "        results = []\n",
        "        current_entry = next((entry for entry in sections_info if entry['title'] == section_title), None)\n",
        "\n",
        "        if not current_entry:\n",
        "            return results\n",
        "\n",
        "        current_level = current_entry['level']\n",
        "        if current_level > 1:\n",
        "            index_of_current = sections_info.index(current_entry)\n",
        "            for entry in reversed(sections_info[:index_of_current]):\n",
        "                if entry['level'] == current_level - 1:\n",
        "                    results.insert(0, (entry['title'], entry['page']))\n",
        "                    current_level -= 1\n",
        "                    if current_level == 1:\n",
        "                        break\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def cleanup(self):\n",
        "            # Get the directory where the PDF file is located\n",
        "            directory = Path(self.source_pdf).parent\n",
        "            base_name = Path(self.base_name).name\n",
        "\n",
        "\n",
        "            for file in directory.iterdir():\n",
        "                #  Check if the file starts with the base name and it is not a PDF file\n",
        "                if file.is_file():\n",
        "                    if file.stem.startswith(base_name) and file.suffix != '.pdf':\n",
        "                        try:\n",
        "                            os.remove(file)\n",
        "                            print(f\"Deleted: {file}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error deleting {file}: {e}\")\n",
        "                    else:\n",
        "                        print(f\"Skipped (not matching criteria): {file}\")\n",
        "                else:\n",
        "                    print(f\"Skipped (not a file): {file}\")\n",
        "\n",
        "    @classmethod\n",
        "    def process_multiple_pdfs(cls, pdf_directory):\n",
        "        all_nodes = []\n",
        "        for pdf_file in Path(pdf_directory).glob(\"*.pdf\"):\n",
        "            processor = cls(str(pdf_file))\n",
        "            processor.transform_pdf_to_html()\n",
        "            clean_text = processor.load_and_process_html()\n",
        "            processor.write_in_file(clean_text)\n",
        "            nodes = processor.split_text()\n",
        "            toc_entries = processor.process_html_toc()\n",
        "            processor.write_toc_to_csv(toc_entries)\n",
        "            sections_info = processor.read_and_prepare_sections()\n",
        "            processor.add_metadata_to_nodes(nodes, sections_info)\n",
        "            all_nodes.extend(nodes)\n",
        "            processor.cleanup()  # Clean additional files\n",
        "\n",
        "        all_nodes_dict = {n.node_id: n for n in all_nodes}\n",
        "        return all_nodes_dict, all_nodes\n"
      ],
      "metadata": {
        "id": "e9PgkEoC-Yyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process one file"
      ],
      "metadata": {
        "id": "RKGFwS_oMHsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pdf_directory_or_file = \"./data/Mixture_of_Agents.pdf\"\n",
        "\n",
        "if os.path.isfile(pdf_directory_or_file):\n",
        "    processor = PDFContentProcessor(pdf_directory_or_file)\n",
        "    processor.transform_pdf_to_html()\n",
        "    clean_text = processor.load_and_process_html()\n",
        "    processor.write_in_file(clean_text)\n",
        "    nodes = processor.split_text()\n",
        "    toc_entries = processor.process_html_toc()\n",
        "    processor.write_toc_to_csv(toc_entries)\n",
        "    sections_info = processor.read_and_prepare_sections()\n",
        "    processor.add_metadata_to_nodes(nodes, sections_info)\n",
        "    all_nodes_dict = {n.node_id: n for n in nodes}\n",
        "    processor.cleanup()  # Limpiar archivos adicionales\n",
        "else:\n",
        "    all_nodes_dict,nodes  = PDFContentProcessor.process_multiple_pdfs(pdf_directory_or_file)\n",
        "\n",
        "for node_id, node in all_nodes_dict.items():\n",
        "    print(node_id, node.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP8LV76j-fd_",
        "outputId": "fa5650ba-6ced-455b-afb8-dce60d78a3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted: data/Mixture_of_Agents.html\n",
            "Deleted: data/Mixture_of_Agents_output.csv\n",
            "Deleted: data/Mixture_of_Agents.txt\n",
            "Deleted: data/Mixture_of_Agentss.html\n",
            "Skipped (not matching criteria): data/Mixture_of_Agents.pdf\n",
            "Deleted: data/Mixture_of_Agents-html.html\n",
            "Skipped (not matching criteria): data/AIOS.pdf\n",
            "20272c45-75b4-434d-8eac-fafcb7b608aa {'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "29427a73-eff2-4399-8b79-f4ec56845b88 {'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "40d1a29e-38a7-4fcd-b3cb-788d618c3cf0 {'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "1839f53e-759e-460e-844b-c1e98466fc20 {'page': [3], 'section': ['Mixture-of-Agents Methodology'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "efbacbf8-68ce-496b-a68c-bf3a96ee447e {'page': [3, 3], 'section': ['Mixture-of-Agents Methodology', 'Mixture-of-Agents'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "9c09eca2-90a0-47a3-a8d9-01ce4d7ea0b7 {'page': [3, 4], 'section': ['Mixture-of-Agents Methodology', 'Analogy to Mixture-of-Experts'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "c4298d89-7689-4408-81c1-2116730d8078 {'page': [4], 'section': ['Evaluation'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "c1511166-6802-4be1-9b43-a702dd77cf76 {'page': [4], 'section': ['Evaluation'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "2a1798d3-f507-44e2-a88f-7feebfed8de4 {'page': [4, 5], 'section': ['Evaluation', 'Setup'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "ce2db192-dc3b-4aa6-b71e-7553fbb162fe {'page': [4, 5], 'section': ['Evaluation', 'Benchmark Results'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "d05879c2-4c73-4a84-a69b-0f4967b70187 {'page': [4, 5], 'section': ['Evaluation', 'Benchmark Results'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "9cf422d6-a594-42ba-bdc6-d5102e8a6526 {'page': [4, 6], 'section': ['Evaluation', 'What Makes Mixture-of-Agents Work Well?'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "d241ebca-f230-44b4-bb7e-fc50ef7504cd {'page': [4, 6], 'section': ['Evaluation', 'What Makes Mixture-of-Agents Work Well?'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "5006243e-10e1-42a6-a314-d3824c1fd7e4 {'page': [4, 6], 'section': ['Evaluation', 'What Makes Mixture-of-Agents Work Well?'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "ace024bc-96e5-4002-80cb-27cc1dab4e57 {'page': [4, 7], 'section': ['Evaluation', 'Budget and Token Analysis'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "7207daca-a336-4166-9935-8138fbb03690 {'page': [8], 'section': ['Related Work'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "bb88e70c-fec9-434c-b809-54c87bca2b59 {'page': [8, 9], 'section': ['Related Work', 'Model Ensemble'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "74457835-b582-44ee-a81a-0727cc243ce2 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "8dec721f-8961-4d9e-8a99-439a2cbb7d16 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "d59818f1-1d7f-4f78-a995-25e80dfc83d4 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "7c0f8b44-5aa5-4722-9b67-a2abc00fe7fa {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "07611a19-0ef8-4dc9-a160-5e096b018ad9 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "4a3c850a-b841-4820-9c87-79c9a0c26d6e {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "a2377671-2d10-4d00-862d-c30d108588d4 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "808c605b-cfa8-42e6-b255-c669fdf39b16 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "b7b61671-7463-41ea-9d86-4382c7f9da8d {'page': [12], 'section': ['Spearman Correlation using Different Similarity Functions'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "9b664dd2-357e-4031-adb3-f17d9d91621d {'page': [13], 'section': ['LLM Ranker'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "272882ee-b377-4249-b50d-cede22b14f88 {'page': [14], 'section': ['Case Study'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "35b3a578-ad1c-40ff-84da-34727d473579 {'page': [14], 'section': ['MATH Task'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "8adcec3a-61d4-4b0c-b134-474e8700413c {'page': [14], 'section': ['MATH Task'], 'file_name': 'Mixture_of_Agents.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process multiple files"
      ],
      "metadata": {
        "id": "4ZuCMrXdMRxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_directory_or_file = \"./data/\"\n",
        "\n",
        "if os.path.isfile(pdf_directory_or_file):\n",
        "    processor = PDFContentProcessor(pdf_directory_or_file)\n",
        "    processor.transform_pdf_to_html()\n",
        "    clean_text = processor.load_and_process_html()\n",
        "    processor.write_in_file(clean_text)\n",
        "    nodes = processor.split_text()\n",
        "    toc_entries = processor.process_html_toc()\n",
        "    processor.write_toc_to_csv(toc_entries)\n",
        "    sections_info = processor.read_and_prepare_sections()\n",
        "    processor.add_metadata_to_nodes(nodes, sections_info)\n",
        "    all_nodes_dict = {n.node_id: n for n in nodes}\n",
        "    processor.cleanup()  # Limpiar archivos adicionales\n",
        "else:\n",
        "    all_nodes_dict,nodes  = PDFContentProcessor.process_multiple_pdfs(pdf_directory_or_file)\n",
        "\n",
        "for node_id, node in all_nodes_dict.items():\n",
        "    print(node_id, node.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWBOkxMlLixt",
        "outputId": "a736eca3-661a-4830-dc61-273d3b4d0462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted: data/Mixture_of_Agents.html\n",
            "Deleted: data/Mixture_of_Agents_output.csv\n",
            "Deleted: data/Mixture_of_Agents.txt\n",
            "Deleted: data/Mixture_of_Agentss.html\n",
            "Skipped (not matching criteria): data/Mixture_of_Agents.pdf\n",
            "Deleted: data/Mixture_of_Agents-html.html\n",
            "Skipped (not matching criteria): data/AIOS.pdf\n",
            "Deleted: data/AIOS_output.csv\n",
            "Deleted: data/AIOS-html.html\n",
            "Deleted: data/AIOSs.html\n",
            "Skipped (not matching criteria): data/Mixture_of_Agents.pdf\n",
            "Skipped (not matching criteria): data/AIOS.pdf\n",
            "Deleted: data/AIOS.html\n",
            "Deleted: data/AIOS.txt\n",
            "72f253f3-dff0-46ea-8676-d116beaa972c {'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "75931586-0dee-4525-a38d-7b8209bb596d {'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "af7a69fe-da88-43ae-a6c5-a42954de08df {'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "3dfd36a1-384f-4fef-b46f-9eebed575352 {'page': [3], 'section': ['Mixture-of-Agents Methodology'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "84a6a5e1-e706-40f1-bb51-0bb19370e456 {'page': [3, 3], 'section': ['Mixture-of-Agents Methodology', 'Mixture-of-Agents'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "66bf3c77-6ea8-432f-9a25-0be518721469 {'page': [3, 4], 'section': ['Mixture-of-Agents Methodology', 'Analogy to Mixture-of-Experts'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "7787a911-fc70-42c1-86bb-389c9e0447e9 {'page': [4], 'section': ['Evaluation'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "04abf83d-56a8-4a28-b020-a704d2988a8d {'page': [4], 'section': ['Evaluation'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "7321375a-7935-47c7-8f31-7671991241d3 {'page': [4, 5], 'section': ['Evaluation', 'Setup'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "6516d3f8-4257-48e3-a7c5-428862b2af1e {'page': [4, 5], 'section': ['Evaluation', 'Benchmark Results'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "4b66ee69-1acb-4eb9-8211-49b026a64fc0 {'page': [4, 5], 'section': ['Evaluation', 'Benchmark Results'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "fe8c2cfb-7a7d-4983-a6ea-9d97a12cd1e0 {'page': [4, 6], 'section': ['Evaluation', 'What Makes Mixture-of-Agents Work Well?'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "48c8521a-244f-4328-940c-915ab45833e8 {'page': [4, 6], 'section': ['Evaluation', 'What Makes Mixture-of-Agents Work Well?'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "d1cacd2a-a3f7-46b9-911f-72a5dd538dda {'page': [4, 6], 'section': ['Evaluation', 'What Makes Mixture-of-Agents Work Well?'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "82d3d7b0-a257-46e3-946e-f8a31a517347 {'page': [4, 7], 'section': ['Evaluation', 'Budget and Token Analysis'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "54c780eb-cbd4-4b71-a08c-4ff13533d70c {'page': [8], 'section': ['Related Work'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "52fb589f-7bbf-4d04-88f8-9df873e1f7b7 {'page': [8, 9], 'section': ['Related Work', 'Model Ensemble'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "4c9858e6-2c99-4142-848a-dfef39ee74f6 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "0c44839a-6a5a-4700-8df8-2aece7b42fe6 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "909b0a23-e705-498a-9248-a8f38787f956 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "74ab1e8a-06c5-409d-aba1-4501afe1eaea {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "1af5bed6-f59f-4a88-9f93-72e4a4921ccb {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "b45753ba-2d9a-4191-b832-71c963cb475c {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "84b4fb9e-61ed-4761-be37-054394472eb7 {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "14808069-00b8-42d6-8d15-513f9d8ddbcf {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "5e38040a-5a08-4da3-af61-ddb499ce6204 {'page': [12], 'section': ['Spearman Correlation using Different Similarity Functions'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "55053023-2ec2-4fb4-8b34-cb128e537f86 {'page': [13], 'section': ['LLM Ranker'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "873a9e7b-47c4-4ff2-8b77-484af6051c6e {'page': [14], 'section': ['Case Study'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "fcc0f2a7-1d6c-4947-9727-39bbdb4c1f74 {'page': [14], 'section': ['MATH Task'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "2836b37c-4734-49cb-a7be-43d4ef8cd9dc {'page': [14], 'section': ['MATH Task'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "d822aea5-112b-43f7-83ab-6605225a9804 {'page': [1], 'section': ['Introduction'], 'file_name': 'AIOS.pdf'}\n",
            "7e97bdae-a2a6-496e-bfa2-d848b954e29c {'page': [1], 'section': ['Introduction'], 'file_name': 'AIOS.pdf'}\n",
            "e1c1977a-0ed9-486e-a5b0-2f4a2f7b112c {'page': [1], 'section': ['Introduction'], 'file_name': 'AIOS.pdf'}\n",
            "e30b6c8d-dc4d-460c-acbd-52d8ce81d951 {'page': [5, 5], 'section': ['AIOS Implementation', 'Agent Scheduler'], 'file_name': 'AIOS.pdf'}\n",
            "a589270d-276a-4bc3-afcc-54ab0d59d1c7 {'page': [3, 3], 'section': ['Related Work', 'Evolution of Operating Systems'], 'file_name': 'AIOS.pdf'}\n",
            "2e014751-3344-478d-ac01-237d4f36aca8 {'page': [3, 3], 'section': ['Related Work', 'Evolution of Operating Systems'], 'file_name': 'AIOS.pdf'}\n",
            "8ad92580-2618-4262-8f32-8d09b8557dfb {'page': [4], 'section': ['AIOS Layers'], 'file_name': 'AIOS.pdf'}\n",
            "9dd27ae7-6c82-4b61-b0f9-931f587a3acf {'page': [5], 'section': ['AIOS Implementation'], 'file_name': 'AIOS.pdf'}\n",
            "423bf25a-cd30-4885-8c16-19a8cbb7825b {'page': [5, 5], 'section': ['AIOS Implementation', 'Context Manager'], 'file_name': 'AIOS.pdf'}\n",
            "72746ffd-1f6b-423e-bf96-028a56460cd0 {'page': [5, 5], 'section': ['AIOS Implementation', 'Context Manager'], 'file_name': 'AIOS.pdf'}\n",
            "5997d0c1-4623-4ac0-8527-6defd50a5ed0 {'page': [5, 5], 'section': ['AIOS Implementation', 'Context Manager'], 'file_name': 'AIOS.pdf'}\n",
            "277f8c39-beed-450d-8d04-52b6b1bf4ce7 {'page': [5, 6], 'section': ['AIOS Implementation', 'Memory Manager'], 'file_name': 'AIOS.pdf'}\n",
            "d3967f01-0b96-499f-81d7-8d309fa3b399 {'page': [5, 7], 'section': ['AIOS Implementation', 'Tool Manager'], 'file_name': 'AIOS.pdf'}\n",
            "7b29e475-8bb5-47d9-8446-182eb27a434f {'page': [5, 7], 'section': ['AIOS Implementation', 'Access Manager'], 'file_name': 'AIOS.pdf'}\n",
            "d62954c2-ff90-4f09-835f-d74e46a7f04f {'page': [5, 8], 'section': ['AIOS Implementation', 'AIOS SDK'], 'file_name': 'AIOS.pdf'}\n",
            "c9b45b45-fefd-4101-b6ee-eefdb9b11db6 {'page': [5, 8], 'section': ['AIOS Implementation', 'AIOS SDK'], 'file_name': 'AIOS.pdf'}\n",
            "f02a8373-3c4c-4f0f-9a7a-d9bf9efa29b6 {'page': [8, 8], 'section': ['Evaluation', 'Experimental Results'], 'file_name': 'AIOS.pdf'}\n",
            "6eb614b6-6509-43e9-aecb-3aab2f11cc52 {'page': [8, 8], 'section': ['Evaluation', 'Experimental Results'], 'file_name': 'AIOS.pdf'}\n",
            "b9d598e8-a3f0-4e42-9705-a64e9a0ba7d3 {'page': [9], 'section': ['Conclusions'], 'file_name': 'AIOS.pdf'}\n",
            "6c1761d2-9595-4439-a6d6-f9c890a318c5 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "e8cf5dd5-a646-4551-aa1b-b4610968b359 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "93fa40cb-edd7-4ca6-b859-628bb6902d46 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "c12203a5-09fb-4fc0-8505-cdcfe7a519b2 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "dc687f7a-e71b-4302-a268-2244ee98bad0 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "6bb4e54e-c462-4ade-8ba7-039b20eb1875 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "d3bce2b7-88b5-4097-87f2-bdf46381d91d {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "dcebf958-9eaf-4a12-b7a8-0f7eba16d39d {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "50fceb63-e695-44dd-83fb-143f5e5c37c4 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "b31938e2-9d2b-410c-8d8d-60809d965bbf {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n",
            "61c58ba2-e9ae-4fbe-9c5e-c4f54ff22f18 {'page': [9], 'section': ['Future Work'], 'file_name': 'AIOS.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4E0Y8HmAdlc",
        "outputId": "b73cf771-f567-47c5-ade2-d0eb0dcc9057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Set up the OpenAI API for the LLM and the embedding model.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zdWX7tXZFc-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = 'YOUR_API_KEY'"
      ],
      "metadata": {
        "id": "yI6j9iv1F2j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
        "from llama_index.core import Settings\n",
        "\n",
        "logging.basicConfig(filename='app.log',\n",
        "                    level=logging.DEBUG,\n",
        "                    force=True, # Resets any previous configuration\n",
        "                    )\n",
        "\n",
        "# Using the LlamaDebugHandler to print the trace\n",
        "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
        "callback_manager = CallbackManager([llama_debug])\n",
        "\n",
        "Settings.callback_manager = callback_manager"
      ],
      "metadata": {
        "id": "uRZF_RAuGPTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.settings import Settings\n",
        "\n",
        "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
        "\n",
        "llm_gpt35t = OpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", callback_manager=callback_manager)"
      ],
      "metadata": {
        "id": "yIiG09DXGIST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Metafilters with embeddings"
      ],
      "metadata": {
        "id": "Ty-OVBvwN_9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes[18].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atZTTnuZLUuf",
        "outputId": "6b689408-4937-44d4-a9e6-90a828d11405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes[48].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlL1uszZMgqk",
        "outputId": "12f8f659-9901-4cdd-d136-a5ca05bf5e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page': [9], 'section': ['Conclusions'], 'file_name': 'AIOS.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1) Search for similarity in metadata without applying weights\n"
      ],
      "metadata": {
        "id": "BcUe68xdmAhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import openai\n",
        "\n",
        "class EmbeddingFilter:\n",
        "    def __init__(self, api_key, model_name=\"text-embedding-ada-002\"):\n",
        "        self.openai_client = openai.Client(api_key=api_key)\n",
        "        self.embedding_model = model_name\n",
        "        self.calculated_section_embeddings = {}\n",
        "        self.node_embeddings = {}\n",
        "\n",
        "    def get_embedding(self, text):\n",
        "        \"\"\"Obtain the embedding of a text using OpenAI's API.\"\"\"\n",
        "        response = self.openai_client.embeddings.create(\n",
        "            input=[text],\n",
        "            model=self.embedding_model,\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "\n",
        "    def process_nodes(self, nodes):\n",
        "        \"\"\"Process each node to calculate and store embeddings.\"\"\"\n",
        "        for node_index, node in enumerate(nodes, start=1):\n",
        "            # Extract the section text from the metadata\n",
        "            section_text = node.metadata.get('section', [''])[0]\n",
        "           # print(section_text)\n",
        "\n",
        "            if section_text:\n",
        "                # If the embedding for this section has already been calculated, reuse it\n",
        "                if section_text not in self.calculated_section_embeddings:\n",
        "                    self.calculated_section_embeddings[section_text] = self.get_embedding(section_text)\n",
        "\n",
        "                # Assign the embedding and the node ID to the node_embeddings dictionary\n",
        "                self.node_embeddings[node_index] = self.calculated_section_embeddings[section_text]\n",
        "\n",
        "    def search_similarity(self, query, similarity_threshold=0.75, top_k=5):\n",
        "        \"\"\"Search for similarity between the query embedding and node embeddings.\"\"\"\n",
        "        # Obtain the embedding of the query\n",
        "        query_embedding = np.array(self.get_embedding(query)).reshape(1, -1)\n",
        "\n",
        "        # List to store results\n",
        "        results = []\n",
        "\n",
        "        # Calculate similarity with each embedding in node_embeddings\n",
        "        for node_id, node_embedding in self.node_embeddings.items():\n",
        "            node_embedding = np.array(node_embedding).reshape(1, -1)\n",
        "            similarity = cosine_similarity(query_embedding, node_embedding)[0][0]\n",
        "\n",
        "            # Filter by similarity threshold\n",
        "            if similarity >= similarity_threshold:\n",
        "                results.append((node_id, similarity))\n",
        "\n",
        "        # Sort the results by similarity in descending order\n",
        "        sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Return the top_k results\n",
        "        return sorted_results[:top_k]\n",
        "\n"
      ],
      "metadata": {
        "id": "D6nnC6SzmDDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the class with your OpenAI API key\n",
        "api_key = 'YOUR_API_KEY'\n",
        "processor = EmbeddingFilter(api_key)\n",
        "\n",
        "# Assume `nodes` is a list of node objects with the required structure\n",
        "# Process nodes to calculate and store embeddings\n",
        "processor.process_nodes(nodes)\n",
        "\n",
        "# Define the query and search parameters\n",
        "query = \"Conclusion\"\n",
        "similarity_threshold = 0.8\n",
        "top_k = 10\n",
        "\n",
        "# Find the most similar nodes to the query\n",
        "similarity_results = processor.search_similarity(query, similarity_threshold, top_k)\n",
        "\n",
        "# Retrieve the complete nodes for the obtained results\n",
        "resulting_nodes = [nodes[node_id - 1] for node_id, _ in similarity_results]\n",
        "\n",
        "# Print the results\n",
        "for node in resulting_nodes:\n",
        "    print(f\"Node ID: {node.id_}\")\n",
        "    print(f\"Similarity: {next(sim for node_id, sim in similarity_results if node_id == nodes.index(node) + 1):.4f}\")\n",
        "    print(f\"Metadata: {node.metadata}\")\n",
        "    print(f\"Text: {node.text[:200]}...\")  # Show a portion of the node's text\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Print all metadata of the resulting nodes\n",
        "for node in resulting_nodes:\n",
        "    print(node.metadata)\n",
        "    print(\"-\" * 50)  # Separator between nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ky__xHOmpEg",
        "outputId": "7b3f963a-d987-48dc-9276-01bf4d77707b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node ID: 4c9858e6-2c99-4142-848a-dfef39ee74f6\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: Additionally, FrugalGPT\n",
            "(Chen et al., 2023b)\n",
            "proposed reducing the cost of using LLMs\n",
            "by employing different models in a cascading manner. In order to better leverage the responses of\n",
            "multiple models,...\n",
            "--------------------------------------------------\n",
            "Node ID: 0c44839a-6a5a-4700-8df8-2aece7b42fe6\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: In\n",
            "addition, we provide insights into improving the design of MoA; systematic optimization of MoA\n",
            "architecture is an interesting direction for future work.\n",
            "\n",
            "Limitations.\n",
            "\n",
            "Our proposed method requires ...\n",
            "--------------------------------------------------\n",
            "Node ID: 909b0a23-e705-498a-9248-a8f38787f956\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: arXiv preprint arXiv:2309.13007\n",
            ", 2023a.\n",
            "\n",
            "Chen, L., Zaharia, M., and Zou, J. Frugalgpt: How to use large language models while reducing cost\n",
            "and improving performance.\n",
            "\n",
            "arXiv preprint arXiv:2305.05176...\n",
            "--------------------------------------------------\n",
            "Node ID: 74ab1e8a-06c5-409d-aba1-4501afe1eaea\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: arXiv preprint arXiv:2401.14196\n",
            ", 2024.\n",
            "\n",
            "Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J.\n",
            "\n",
            "Measuring mathematical problem solving with the math dat...\n",
            "--------------------------------------------------\n",
            "Node ID: 1af5bed6-f59f-4a88-9f93-72e4a4921ccb\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: Association for Computational Linguistics.\n",
            "\n",
            "doi: 10.18653/v1/2023.acl-long.792. URL\n",
            "https://aclanthology.org/2023.acl-long.\n",
            "\n",
            "792\n",
            ".\n",
            "\n",
            "Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large l...\n",
            "--------------------------------------------------\n",
            "Node ID: b45753ba-2d9a-4191-b832-71c963cb475c\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: URL\n",
            "https://aclanthology.org/P02-1040/\n",
            ".\n",
            "\n",
            "RapidFuzz.\n",
            "\n",
            "python-levenshtein\n",
            "by\n",
            "rapidfuzz.\n",
            "\n",
            "https://github.com/rapidfuzz/\n",
            "python-Levenshtein\n",
            ",\n",
            "2023.\n",
            "\n",
            "Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Ga...\n",
            "--------------------------------------------------\n",
            "Node ID: 84b4fb9e-61ed-4761-be37-054394472eb7\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: Llama: Open and efficient foundation language models.\n",
            "\n",
            "arXiv\n",
            "preprint arXiv:2302.13971\n",
            ", 2023a.\n",
            "\n",
            "Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S.,\n",
            "Bh...\n",
            "--------------------------------------------------\n",
            "Node ID: 14808069-00b8-42d6-8d15-513f9d8ddbcf\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: 11\n",
            "0.00\n",
            "0.05\n",
            "0.10\n",
            "0.15\n",
            "0.20\n",
            "0.25\n",
            "Spearman correlation coefficient\n",
            "QWen1.5-110B\n",
            "QWen1.5-72B\n",
            "WizardLM\n",
            "Llama-3-70B\n",
            "Mixtral-8x22B\n",
            "dbrx-instruct\n",
            "Aggr\n",
            "egator\n",
            "Aggregation\n",
            "1st aggregation\n",
            "2nd aggregation\n",
            "3rd ...\n",
            "--------------------------------------------------\n",
            "Node ID: b9d598e8-a3f0-4e42-9705-a64e9a0ba7d3\n",
            "Similarity: 0.8964\n",
            "Metadata: {'page': [9], 'section': ['Conclusions'], 'file_name': 'AIOS.pdf'}\n",
            "Text: Table 5: Effectiveness of agent scheduling, compared with non-scheduled (sequential) execution.\n",
            "\n",
            "LLM backbone\n",
            "Agent\n",
            "Sequential execution (non-scheduled)\n",
            "Concurrent execution (scheduled)\n",
            "Waiting time (...\n",
            "--------------------------------------------------\n",
            "Node ID: 72f253f3-dff0-46ea-8676-d116beaa972c\n",
            "Similarity: 0.8873\n",
            "Metadata: {'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: Mixture-of-Agents Enhances Large Language Model\n",
            "Capabilities\n",
            "Junlin Wang\n",
            "Duke University\n",
            "Together AI\n",
            "junlin.wang2@duke.edu\n",
            "Jue Wang\n",
            "Together AI\n",
            "jue@together.ai\n",
            "Ben Athiwaratkun\n",
            "Together AI\n",
            "ben@togethe...\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusions'], 'file_name': 'AIOS.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [1], 'section': ['Introduction'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2) Search similarity in metadata applying different weights and normalization"
      ],
      "metadata": {
        "id": "yV5wTsrklSX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize, minmax_scale\n",
        "import openai\n",
        "\n",
        "class EmbeddingProcessor:\n",
        "    def __init__(self, api_key, model_name=\"text-embedding-ada-002\", weight_word=\"Conclusion\", weight_factor=1.5):\n",
        "        self.openai_client = openai.Client(api_key=api_key)\n",
        "        self.embedding_model = model_name\n",
        "        self.weight_word = weight_word\n",
        "        self.weight_factor = weight_factor\n",
        "        self.calculated_section_embeddings = {}\n",
        "        self.node_embeddings = {}\n",
        "\n",
        "    def get_embedding(self, text):\n",
        "        \"\"\"Obtain the embedding of a text using OpenAI's API.\"\"\"\n",
        "        response = self.openai_client.embeddings.create(\n",
        "            input=[text],\n",
        "            model=self.embedding_model,\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "\n",
        "    def get_weighted_embedding(self, section_text):\n",
        "        \"\"\"Obtain and normalize the embedding of a text with custom weighting.\"\"\"\n",
        "        embedding = self.get_embedding(section_text)\n",
        "\n",
        "        # Apply custom weights: increase weight if the section contains the weight word\n",
        "        weight = self.weight_factor if self.weight_word in section_text else 1.0\n",
        "        weighted_embedding = np.array(embedding) * weight\n",
        "\n",
        "        # Normalize the weighted embedding\n",
        "        normalized_embedding = normalize([weighted_embedding], norm='l2')[0]\n",
        "        return normalized_embedding\n",
        "\n",
        "    def process_nodes(self, nodes):\n",
        "        \"\"\"Process each node to calculate and store embeddings.\"\"\"\n",
        "        for node_index, node in enumerate(nodes, start=1):\n",
        "            section_text = node.metadata.get('section', [''])[0]\n",
        "           #print(section_text)\n",
        "\n",
        "            if section_text:\n",
        "                # If the embedding for this section has already been calculated, reuse it\n",
        "                if section_text not in self.calculated_section_embeddings:\n",
        "                    self.calculated_section_embeddings[section_text] = self.get_weighted_embedding(section_text)\n",
        "\n",
        "                # Assign the embedding and the node ID to the node_embeddings dictionary\n",
        "                self.node_embeddings[node_index] = self.calculated_section_embeddings[section_text]\n",
        "\n",
        "    def search_similarity(self, query, nodes, similarity_threshold=0.75, top_k=5):\n",
        "        \"\"\"Search for similarity between the query embedding and node embeddings.\"\"\"\n",
        "        # Obtain the embedding of the query\n",
        "        query_embedding = np.array(self.get_weighted_embedding(query)).reshape(1, -1)\n",
        "\n",
        "        # List to store results\n",
        "        results = []\n",
        "\n",
        "        # Calculate similarity with each embedding in node_embeddings\n",
        "        for node_id, node_embedding in self.node_embeddings.items():\n",
        "            node_embedding = np.array(node_embedding).reshape(1, -1)\n",
        "            similarity = cosine_similarity(query_embedding, node_embedding)[0][0]\n",
        "\n",
        "            # Apply additional scaling if the section contains the weight word\n",
        "            section_text = nodes[node_id - 1].metadata.get('section', [''])[0]\n",
        "            if self.weight_word in section_text:\n",
        "                similarity *= self.weight_factor  # Increase similarity score for sections containing the weight word\n",
        "\n",
        "            results.append((node_id, similarity))\n",
        "\n",
        "        # Rescale the similarity scores between 0 and 1\n",
        "        similarities = [sim for _, sim in results]\n",
        "        rescaled_similarities = minmax_scale(similarities, feature_range=(0, 1))\n",
        "\n",
        "        # Assign the rescaled similarities back to the results\n",
        "        rescaled_results = [(node_id, sim) for (node_id, _), sim in zip(results, rescaled_similarities)]\n",
        "\n",
        "        # Filter by similarity threshold\n",
        "        rescaled_results = [(node_id, sim) for node_id, sim in rescaled_results if sim >= similarity_threshold]\n",
        "\n",
        "        # Sort the results by similarity in descending order\n",
        "        sorted_results = sorted(rescaled_results, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Return the top_k results\n",
        "        return sorted_results[:top_k]\n",
        "\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# Initialize the class with your OpenAI API key and the word to weight\n",
        "api_key = 'YOUR_API_KEY'\n",
        "processor = EmbeddingProcessor(api_key, weight_word=\"Conclu\", weight_factor=1.5)\n",
        "\n",
        "# Assume `nodes` is a list of node objects with the required structure\n",
        "# Process nodes to calculate and store embeddings\n",
        "processor.process_nodes(nodes)\n",
        "\n",
        "# Define the query and search parameters\n",
        "query = \"Conclusion\"\n",
        "similarity_threshold = 0.7\n",
        "top_k = 15\n",
        "\n",
        "# Find the most similar nodes to the query\n",
        "similarity_results = processor.search_similarity(query, nodes, similarity_threshold, top_k)\n",
        "\n",
        "# Retrieve the complete nodes for the obtained results\n",
        "resulting_nodes = [nodes[node_id - 1] for node_id, _ in similarity_results]\n",
        "\n",
        "# Print the results\n",
        "for node in resulting_nodes:\n",
        "    print(f\"Node ID: {node.id_}\")\n",
        "    print(f\"Similarity: {next(sim for node_id, sim in similarity_results if node_id == nodes.index(node) + 1):.4f}\")\n",
        "    print(f\"Metadata: {node.metadata}\")\n",
        "    print(f\"Text: {node.text[:200]}...\")  # Show a portion of the node's text\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Print all metadata of the resulting nodes\n",
        "for node in resulting_nodes:\n",
        "    print(node.metadata)\n",
        "    print(\"-\" * 50)  # Separator between nodes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh96eY7GpuB9",
        "outputId": "270bc108-b7c8-45c5-f659-33a10720ed37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node ID: 4c9858e6-2c99-4142-848a-dfef39ee74f6\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: Additionally, FrugalGPT\n",
            "(Chen et al., 2023b)\n",
            "proposed reducing the cost of using LLMs\n",
            "by employing different models in a cascading manner. In order to better leverage the responses of\n",
            "multiple models,...\n",
            "--------------------------------------------------\n",
            "Node ID: 0c44839a-6a5a-4700-8df8-2aece7b42fe6\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: In\n",
            "addition, we provide insights into improving the design of MoA; systematic optimization of MoA\n",
            "architecture is an interesting direction for future work.\n",
            "\n",
            "Limitations.\n",
            "\n",
            "Our proposed method requires ...\n",
            "--------------------------------------------------\n",
            "Node ID: 909b0a23-e705-498a-9248-a8f38787f956\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: arXiv preprint arXiv:2309.13007\n",
            ", 2023a.\n",
            "\n",
            "Chen, L., Zaharia, M., and Zou, J. Frugalgpt: How to use large language models while reducing cost\n",
            "and improving performance.\n",
            "\n",
            "arXiv preprint arXiv:2305.05176...\n",
            "--------------------------------------------------\n",
            "Node ID: 74ab1e8a-06c5-409d-aba1-4501afe1eaea\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: arXiv preprint arXiv:2401.14196\n",
            ", 2024.\n",
            "\n",
            "Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J.\n",
            "\n",
            "Measuring mathematical problem solving with the math dat...\n",
            "--------------------------------------------------\n",
            "Node ID: 1af5bed6-f59f-4a88-9f93-72e4a4921ccb\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: Association for Computational Linguistics.\n",
            "\n",
            "doi: 10.18653/v1/2023.acl-long.792. URL\n",
            "https://aclanthology.org/2023.acl-long.\n",
            "\n",
            "792\n",
            ".\n",
            "\n",
            "Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large l...\n",
            "--------------------------------------------------\n",
            "Node ID: b45753ba-2d9a-4191-b832-71c963cb475c\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: URL\n",
            "https://aclanthology.org/P02-1040/\n",
            ".\n",
            "\n",
            "RapidFuzz.\n",
            "\n",
            "python-levenshtein\n",
            "by\n",
            "rapidfuzz.\n",
            "\n",
            "https://github.com/rapidfuzz/\n",
            "python-Levenshtein\n",
            ",\n",
            "2023.\n",
            "\n",
            "Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Ga...\n",
            "--------------------------------------------------\n",
            "Node ID: 84b4fb9e-61ed-4761-be37-054394472eb7\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: Llama: Open and efficient foundation language models.\n",
            "\n",
            "arXiv\n",
            "preprint arXiv:2302.13971\n",
            ", 2023a.\n",
            "\n",
            "Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S.,\n",
            "Bh...\n",
            "--------------------------------------------------\n",
            "Node ID: 14808069-00b8-42d6-8d15-513f9d8ddbcf\n",
            "Similarity: 1.0000\n",
            "Metadata: {'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "Text: 11\n",
            "0.00\n",
            "0.05\n",
            "0.10\n",
            "0.15\n",
            "0.20\n",
            "0.25\n",
            "Spearman correlation coefficient\n",
            "QWen1.5-110B\n",
            "QWen1.5-72B\n",
            "WizardLM\n",
            "Llama-3-70B\n",
            "Mixtral-8x22B\n",
            "dbrx-instruct\n",
            "Aggr\n",
            "egator\n",
            "Aggregation\n",
            "1st aggregation\n",
            "2nd aggregation\n",
            "3rd ...\n",
            "--------------------------------------------------\n",
            "Node ID: b9d598e8-a3f0-4e42-9705-a64e9a0ba7d3\n",
            "Similarity: 0.8029\n",
            "Metadata: {'page': [9], 'section': ['Conclusions'], 'file_name': 'AIOS.pdf'}\n",
            "Text: Table 5: Effectiveness of agent scheduling, compared with non-scheduled (sequential) execution.\n",
            "\n",
            "LLM backbone\n",
            "Agent\n",
            "Sequential execution (non-scheduled)\n",
            "Concurrent execution (scheduled)\n",
            "Waiting time (...\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusion'], 'file_name': 'Mixture_of_Agents.pdf'}\n",
            "--------------------------------------------------\n",
            "{'page': [9], 'section': ['Conclusions'], 'file_name': 'AIOS.pdf'}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Querying"
      ],
      "metadata": {
        "id": "MkoJMmj69Obp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Transform vector store index (Llama Index)"
      ],
      "metadata": {
        "id": "kWruk92-OamU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
        "from llama_index.core import Settings\n",
        "\n",
        "logging.basicConfig(filename='app.log',\n",
        "                    level=logging.DEBUG,\n",
        "                    force=True,\n",
        "                    )\n",
        "\n",
        "# Using the LlamaDebugHandler to print the trace\n",
        "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
        "callback_manager = CallbackManager([llama_debug])\n",
        "\n",
        "Settings.callback_manager = callback_manager\n",
        "from llama_index.core.schema import TextNode\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# Function to convert a node into a TextNode\n",
        "def convert_to_text_node(node, similarity):\n",
        "    return TextNode(\n",
        "        id_=node.id_,\n",
        "        text=node.text,\n",
        "        metadata={\n",
        "            'section': node.metadata.get('section', [''])[0],\n",
        "            'file_name': node.metadata.get('file_name', [''])[0],\n",
        "            'similarity_score': round(similarity, 4)  # Adding similarity score as part of metadata\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Get the actual nodes from the node_id in similarity_results\n",
        "resulting_nodes = [(nodes[node_id - 1], similarity) for node_id, similarity in similarity_results]\n",
        "\n",
        "# Convert node results to a TextNode list\n",
        "text_nodes = [convert_to_text_node(node, similarity) for node, similarity in resulting_nodes]\n",
        "\n",
        "\n",
        "for text_node in text_nodes:\n",
        "    print(f\"Node ID: {text_node.id_}\")\n",
        "    print(f\"Similarity: {text_node.metadata['similarity_score']:.4f}\")\n",
        "    print(f\"Metadata: {text_node.metadata}\")\n",
        "    print(f\"Text: {text_node.text[:200]}...\")  # Displays a portion of the node text\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "for text_node in text_nodes:\n",
        "    print(text_node.metadata)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZrXqo8uOvo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20592181-0b27-4ffb-fccd-0114b0061c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node ID: 4c9858e6-2c99-4142-848a-dfef39ee74f6\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: Additionally, FrugalGPT\n",
            "(Chen et al., 2023b)\n",
            "proposed reducing the cost of using LLMs\n",
            "by employing different models in a cascading manner. In order to better leverage the responses of\n",
            "multiple models,...\n",
            "--------------------------------------------------\n",
            "Node ID: 0c44839a-6a5a-4700-8df8-2aece7b42fe6\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: In\n",
            "addition, we provide insights into improving the design of MoA; systematic optimization of MoA\n",
            "architecture is an interesting direction for future work.\n",
            "\n",
            "Limitations.\n",
            "\n",
            "Our proposed method requires ...\n",
            "--------------------------------------------------\n",
            "Node ID: 909b0a23-e705-498a-9248-a8f38787f956\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: arXiv preprint arXiv:2309.13007\n",
            ", 2023a.\n",
            "\n",
            "Chen, L., Zaharia, M., and Zou, J. Frugalgpt: How to use large language models while reducing cost\n",
            "and improving performance.\n",
            "\n",
            "arXiv preprint arXiv:2305.05176...\n",
            "--------------------------------------------------\n",
            "Node ID: 74ab1e8a-06c5-409d-aba1-4501afe1eaea\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: arXiv preprint arXiv:2401.14196\n",
            ", 2024.\n",
            "\n",
            "Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J.\n",
            "\n",
            "Measuring mathematical problem solving with the math dat...\n",
            "--------------------------------------------------\n",
            "Node ID: 1af5bed6-f59f-4a88-9f93-72e4a4921ccb\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: Association for Computational Linguistics.\n",
            "\n",
            "doi: 10.18653/v1/2023.acl-long.792. URL\n",
            "https://aclanthology.org/2023.acl-long.\n",
            "\n",
            "792\n",
            ".\n",
            "\n",
            "Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large l...\n",
            "--------------------------------------------------\n",
            "Node ID: b45753ba-2d9a-4191-b832-71c963cb475c\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: URL\n",
            "https://aclanthology.org/P02-1040/\n",
            ".\n",
            "\n",
            "RapidFuzz.\n",
            "\n",
            "python-levenshtein\n",
            "by\n",
            "rapidfuzz.\n",
            "\n",
            "https://github.com/rapidfuzz/\n",
            "python-Levenshtein\n",
            ",\n",
            "2023.\n",
            "\n",
            "Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Ga...\n",
            "--------------------------------------------------\n",
            "Node ID: 84b4fb9e-61ed-4761-be37-054394472eb7\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: Llama: Open and efficient foundation language models.\n",
            "\n",
            "arXiv\n",
            "preprint arXiv:2302.13971\n",
            ", 2023a.\n",
            "\n",
            "Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S.,\n",
            "Bh...\n",
            "--------------------------------------------------\n",
            "Node ID: 14808069-00b8-42d6-8d15-513f9d8ddbcf\n",
            "Similarity: 1.0000\n",
            "Metadata: {'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "Text: 11\n",
            "0.00\n",
            "0.05\n",
            "0.10\n",
            "0.15\n",
            "0.20\n",
            "0.25\n",
            "Spearman correlation coefficient\n",
            "QWen1.5-110B\n",
            "QWen1.5-72B\n",
            "WizardLM\n",
            "Llama-3-70B\n",
            "Mixtral-8x22B\n",
            "dbrx-instruct\n",
            "Aggr\n",
            "egator\n",
            "Aggregation\n",
            "1st aggregation\n",
            "2nd aggregation\n",
            "3rd ...\n",
            "--------------------------------------------------\n",
            "Node ID: b9d598e8-a3f0-4e42-9705-a64e9a0ba7d3\n",
            "Similarity: 0.8029\n",
            "Metadata: {'section': 'Conclusions', 'file_name': 'A', 'similarity_score': 0.8029}\n",
            "Text: Table 5: Effectiveness of agent scheduling, compared with non-scheduled (sequential) execution.\n",
            "\n",
            "LLM backbone\n",
            "Agent\n",
            "Sequential execution (non-scheduled)\n",
            "Concurrent execution (scheduled)\n",
            "Waiting time (...\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusion', 'file_name': 'M', 'similarity_score': 1.0}\n",
            "--------------------------------------------------\n",
            "{'section': 'Conclusions', 'file_name': 'A', 'similarity_score': 0.8029}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex"
      ],
      "metadata": {
        "id": "AMN1iyM0bVDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the index using the TextNode\n",
        "index = VectorStoreIndex(text_nodes,callback_manager=callback_manager)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB8m2LgrRjVk",
        "outputId": "59d4bd10-f4c3-42ee-838c-cb6a026cb091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********\n",
            "Trace: index_construction\n",
            "    |_embedding -> 0.710751 seconds\n",
            "**********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can use the index for queries\n",
        "query_engine = index.as_query_engine(similarity_top_k=5)\n",
        "response = query_engine.query(\"Which are the conclusions of the AIOS paper?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4AI2N5APqOi",
        "outputId": "a597bc08-db8a-4a18-9549-e38f20a00887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********\n",
            "Trace: query\n",
            "    |_query -> 1.427979 seconds\n",
            "      |_retrieve -> 0.124469 seconds\n",
            "        |_embedding -> 0.121983 seconds\n",
            "      |_synthesize -> 1.302857 seconds\n",
            "        |_templating -> 2.5e-05 seconds\n",
            "        |_llm -> 1.290545 seconds\n",
            "**********\n",
            "The AIOS paper concludes by proposing the AIOS architecture to facilitate the development and deployment of LLM-based agents, aiming to create a more cohesive, effective, and efficient AIOS-Agent ecosystem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "retrieval=query_engine.retrieve('Which are the conclusions of the AIOS paper?')\n",
        "for n in retrieval:\n",
        "  display_source_node(n, source_length=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "6qIgU1jMR_Nv",
        "outputId": "fef27588-815d-46b1-daab-fc43bedd1e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********\n",
            "Trace: query\n",
            "    |_retrieve -> 0.105555 seconds\n",
            "      |_embedding -> 0.102968 seconds\n",
            "**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** b9d598e8-a3f0-4e42-9705-a64e9a0ba7d3<br>**Similarity:** 0.8298229423740328<br>**Text:** Table 5: Effectiveness of agent scheduling, compared with non-scheduled (sequential) execution.\n\nLLM backbone\nAgent\nSequential execution (non-scheduled)\nConcurrent execution (scheduled)\nWaiting time (s)\nTurnaround time (s)\nWaiting time (s)\nTurnaround time (s)\nGemma-2b-it\nMath Agent\n0.002\n±\n0.001\n2.71\n±\n0.53\n2.50\n±\n0.05\n4.18\n±\n0.18\nNarrative Agent\n2.18\n±\n0.53\n3.18\n±\n0.64\n3.34\n±\n0.17\n4.18\n±\n0.18\nRec Agent\n4.78\n±\n0.96\n7.68\n±\n1.27\n3.46\n±\n0.20\n5.91\n±\n0.19\nGemma-7b-it\nMath Agent\n0.002\n±\n0.001\n4.95\n...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 0c44839a-6a5a-4700-8df8-2aece7b42fe6<br>**Similarity:** 0.7963888703283242<br>**Text:** In\naddition, we provide insights into improving the design of MoA; systematic optimization of MoA\narchitecture is an interesting direction for future work.\n\nLimitations.\n\nOur proposed method requires iterative aggregation of model responses, which means\nthe model cannot decide the first token until the last MoA layer is reached. This potentially results\nin a high Time to First Token (TTFT), which can negatively impact user experience. To mitigate\nthis issue, we can limit the number of MoA lay...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 4c9858e6-2c99-4142-848a-dfef39ee74f6<br>**Similarity:** 0.7902552316056137<br>**Text:** Additionally, FrugalGPT\n(Chen et al., 2023b)\nproposed reducing the cost of using LLMs\nby employing different models in a cascading manner. In order to better leverage the responses of\nmultiple models,\nJiang et al. (2023)\ntrained a G\nEN\nF\nUSER\n, a model that was trained to generate an\nimproved response to capitalize on the strengths of multiple candidates.\n\nHuang et al. (2024)\nproposed\nto fuse the outputs of different models by averaging their output probability distributions.\n\nAnother line of...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 1af5bed6-f59f-4a88-9f93-72e4a4921ccb<br>**Similarity:** 0.788824519852953<br>**Text:** Association for Computational Linguistics.\n\ndoi: 10.18653/v1/2023.acl-long.792. URL\nhttps://aclanthology.org/2023.acl-long.\n\n792\n.\n\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot\nreasoners.\n\nAdvances in neural information processing systems\n, 35:22199–22213, 2022.\n\nLiang, T., He, Z., Jiao, W., Wang, X., Wang, Y., Wang, R., Yang, Y., Tu, Z., and Shi, S. Encour-\naging divergent thinking in large language models through multi-agent debate.\n\narXiv...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 84b4fb9e-61ed-4761-be37-054394472eb7<br>**Similarity:** 0.7810925171618581<br>**Text:** Llama: Open and efficient foundation language models.\n\narXiv\npreprint arXiv:2302.13971\n, 2023a.\n\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S.,\nBhargava, P., Bhosale, S., et al. Llama 2: Open foundation and fine-tuned chat models.\n\narXiv\npreprint arXiv:2307.09288\n, 2023b.\n\nWang, H., Polo, F. M., Sun, Y., Kundu, S., Xing, E., and Yurochkin, M. Fusing models with\ncomplementary expertise. In\nThe Twelfth International Conference on Learning Re...<br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Call ChatGPT directly"
      ],
      "metadata": {
        "id": "WCGXb9qJ2M2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"YOUR_API_KEY\")"
      ],
      "metadata": {
        "id": "CGy7NABS2uD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(user_prompt,system_prompt, model=\"gpt-3.5-turbo\"):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "FiZXgu542iQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question='Which are the conclusions of the AIOS paper?'\n",
        "user_prompt=f'Taking account the context \" {text_nodes} \". + {question} '\n",
        "system_prompt = ('''You are an Augmented Retrieval Generation system, you will be provided with a text\n",
        "context for you to answer a question.\n",
        "If the answer is not in the context, it indicates that it cannot be answered with that information.''')\n",
        "get_completion(user_prompt,system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "9-7s3vc34PKu",
        "outputId": "441673a6-3caf-4626-f007-535efe974245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The conclusions of the AIOS paper include proposing the AIOS architecture, which demonstrates the potential to facilitate the development and deployment of LLM-based agents, fostering a more cohesive, effective, and efficient AIOS-Agent ecosystem.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thank you for making it to the end of the tutorial! 🎉 I hope you found everything you needed. Happy coding! 🚀"
      ],
      "metadata": {
        "id": "-NY8NO6ye5P5"
      }
    }
  ]
}